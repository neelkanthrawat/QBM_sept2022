{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkFVBq5GKKoH"
      },
      "outputs": [],
      "source": [
        "## TO RUN WHILE USING GOOGLE-COLAB\n",
        "# !pip install numba --q\n",
        "# !pip install qiskit ipywidgets --q \n",
        "# !wget https://raw.githubusercontent.com/neelkanthrawat/QBM_sept2022/main/qmcmc_codes/qbm_utils_2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4spUofDctBa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import numba\n",
        "from numba import jit, typeof, types\n",
        "import time \n",
        "from qbm_utils_2 import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @jitclass([('J', typeof(J)), ('h', typeof(h)), ('beta', typeof(beta)), ('num_spins', types.float64)])\n",
        "# class tryal:\n",
        "#     \"\"\"A class to build the Ising Hamiltonian from data\"\"\"\n",
        "#     # J: np.array\n",
        "#     # h: np.array\n",
        "#     # beta: float\n",
        "#     def __init__(self, J: np.array, h: np.array, beta: float = 1.0) -> None:\n",
        "#         self.J = J\n",
        "#         self.h = h\n",
        "#         self.beta = beta\n",
        "#         self.num_spins = len(h)\n",
        "    \n",
        "#     @property\n",
        "#     def get_J(self):\n",
        "#         return self.J\n",
        "\n",
        "#     @property\n",
        "#     def get_h(self):\n",
        "#         return self.h\n",
        "\n",
        "    \n",
        "#     def get_energy(self, state: Union[str, np.array]) -> float:\n",
        "#         \"\"\"'state' should be a bipolar state if it is an array\"\"\"\n",
        "\n",
        "#         if isinstance(state, str):\n",
        "#             state = np.array([-1 if elem == \"0\" else 1 for elem in state])\n",
        "#             # state = np.array( [int(list(state)[i]) for i in range(len(state))])\n",
        "#             energy = 0.5 * np.dot(state.transpose(), self.J.dot(state)) + np.dot(\n",
        "#                 self.h.transpose(), state\n",
        "#             )\n",
        "#             return energy\n",
        "#         else:\n",
        "#             return 0.5 * np.dot(state.transpose(), self.J.dot(state)) + np.dot(\n",
        "#                 self.h.transpose(), state\n",
        "#             )\n",
        "#     # @jit(nopython= True)\n",
        "#     def get_partition_sum(self, beta: float = 1.0):  ## is computationally expensive\n",
        "\n",
        "#         all_configs = np.array(list(itertools.product([1, 0], repeat=self.num_spins)))\n",
        "#         return sum([self.get_boltzmann_prob(configbeta=beta) for config in all_configs])\n",
        "\n",
        "#     # @jit(nopython= True)\n",
        "#     def get_boltzmann_prob(\n",
        "#         self, state: Union[str, np.array], beta: float = 1.0, normalised=False\n",
        "#     ) -> float:\n",
        "\n",
        "#         if normalised:\n",
        "#             return np.exp(-1 * beta * self.get_energy(state)) / self.get_partition_sum(\n",
        "#                 beta\n",
        "#             )\n",
        "\n",
        "#         else:\n",
        "#             return np.exp(-1 * beta * self.get_energy(state))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkr0xkNLctBi"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DaTGgKPctBl",
        "outputId": "c64a9b6a-1496-44b9-ed97-b1a6e43ab9b1"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "np.random.seed(1)# should always be in the same cell!  \n",
        "n_spins = 10 * 2\n",
        "\n",
        "## construct problem Hamiltonian ##\n",
        "shape_of_J=(n_spins,n_spins)\n",
        "\n",
        "# defining J matrix (mutual 1-1 interaction)\n",
        "J =  np.round(np.random.uniform(low= -1, high= 1, size = (n_spins,n_spins)), decimals=2)#np.random.uniform(low= -1, high= 1, size= (n_spins, n_spins) )\n",
        "J = 0.5 * (J + J.transpose() )\n",
        "# print(\"J before:\"); print(J)\n",
        "J= J - np.diag(np.diag(J))\n",
        "\n",
        "# J=np.array([[0,1,0.5,-1],[1,0,0.3,0.5],[0.5,0.3,0,1],[-1,0.5,1,0]])\n",
        "# print(\"J after:\", J)\n",
        "\n",
        "# defining h\n",
        "h = np.round(np.random.randn(n_spins), decimals=2)#np.random.uniform(low= -1, high = 1, size= (n_spins))\n",
        "# h=np.array([0.5]*n_spins)\n",
        "# print(\"h is:\", h);\n",
        "\n",
        "# instantiate the model\n",
        "model = IsingEnergyFunction(J, h)\n",
        "# print(model.get_energy('0100'))\n",
        "alpha = np.sqrt(n_spins) / np.sqrt( sum([J[i][j]**2 for i in range(n_spins) for j in range(i)]) + sum([h[j]**2 for j in range(n_spins)])  )\n",
        "# print(\"alpha: \", alpha);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKufwMofctBq"
      },
      "source": [
        "### Get the true distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A3RrDZK_ctBx"
      },
      "outputs": [],
      "source": [
        "# @jit(nopython = True)\n",
        "def true_boltzman_distn(n_spins:int, temp:int, model, wanna_plot=False):\n",
        "\n",
        "    states_nbit=states(num_spins=n_spins)# arranged in ascending order in magnitude\n",
        "    # Actual_probability distribution\n",
        "    transits_bltz = dict( [ ( state, model.get_boltzmann_prob(state, beta=1./temp) ) for state in tqdm(states_nbit) ] )\n",
        "    rqd_sum=np.sum(np.array(list(transits_bltz.values())))\n",
        "    prob_vals=list(np.array(list(transits_bltz.values()))*(1./rqd_sum))\n",
        "    ### unsorted prob distribution\n",
        "    bpd=dict(zip(states_nbit, prob_vals ))### dict of distn, arranged in ascending order of keys\n",
        "    ### Prob distribution, sorted in descending order of prob values\n",
        "    boltz_prob_distn_sorted_desc=value_sorted_dict( bpd, reverse=True )\n",
        "    # plot distribution\n",
        "    if wanna_plot:\n",
        "        plt.figure(2)\n",
        "    plot_bargraph_desc_order(boltz_prob_distn_sorted_desc, label=\"analytical\",plot_first_few=20); plt.legend()\n",
        "    \n",
        "    return boltz_prob_distn_sorted_desc, bpd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1048576/1048576 [02:02<00:00, 8584.55it/s] \n"
          ]
        }
      ],
      "source": [
        "states_nbit=states(num_spins=n_spins)# arranged in ascending order in magnitude\n",
        "# Actual_probability distribution\n",
        "transits_bltz = dict( [ ( state, model.get_boltzmann_prob(state, beta=1./temp) ) for state in tqdm(states_nbit) ] )\n",
        "rqd_sum=np.sum(np.array(list(transits_bltz.values())))\n",
        "prob_vals=list(np.array(list(transits_bltz.values()))*(1./rqd_sum))\n",
        "### unsorted prob distribution\n",
        "bpd=dict(zip(states_nbit, prob_vals ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Zs21bQBjctBy",
        "outputId": "d5275da4-1558-4433-91c7-29b866572987"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1048576/1048576 [01:27<00:00, 11957.38it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "states_nbit=states(num_spins=n_spins)\n",
        "temp=0.4\n",
        "boltz_prob_distn,bpd=true_boltzman_distn(n_spins, temp=temp, model=model, wanna_plot=True)#dict sorted in vals,dict sorted in keys\n",
        "# plot_histogram([bpd], legend=[\"analytical\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1048576/1048576 [00:15<00:00, 69877.12it/s]\n",
            "100%|██████████| 1048576/1048576 [00:19<00:00, 53619.83it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2.3816229657586296, 3.0037438788127804)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entrpy = np.sum([ -1 * pi * np.log2(pi) for pi in tqdm(boltz_prob_distn.values()) ]) \n",
        "var_entrpy = np.sum([ 1 * pi * (np.log2(1/pi))**2 for pi in tqdm(boltz_prob_distn.values()) ])\n",
        "entrpy, np.sqrt(var_entrpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropt_f = lambda x : -1 * x * np.log2(x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1048576/1048576 [00:09<00:00, 114063.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3816229657586296\n",
            "2.3816229657586296\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(9.373958196999979, 0.6778787700000066)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t0 = time.process_time()\n",
        "print( np.sum([ -1 * pi * np.log2(pi) for pi in tqdm(boltz_prob_distn.values()) ]) )\n",
        "t1 = time.process_time()\n",
        "a = np.array(list(boltz_prob_distn.values()))\n",
        "print(np.sum( entropt_f(a) ))\n",
        "t2 = time.process_time()\n",
        "\n",
        "\n",
        "t1-t0, t2-t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truncate_distribution(prob_dist: dict):\n",
        "    \"\"\" Truncate a given probability distribution based n typicality \"\"\"\n",
        "    \n",
        "    lmd_entrpy  = lambda x : -1 * x * np.log2(x) \n",
        "    lmd_entrpy_2 = lambda x : x * (np.log2(x))**2\n",
        "    prob_vals = np.array(list(prob_dist.values()))\n",
        "    \n",
        "    entropy = np.sum(lmd_entrpy(prob_vals))\n",
        "    entropy_var = np.sqrt(np.sum(lmd_entrpy_2(prob_vals)))\n",
        "\n",
        "\n",
        "    for s, prob in value_sorted_dict(prob_dist).items() :\n",
        "        \n",
        "        \n",
        "\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/rajarsi/Documents/QBMS/qbm_git_new/qmcmc_codes/numba_cnvrgnce_analytics.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rajarsi/Documents/QBMS/qbm_git_new/qmcmc_codes/numba_cnvrgnce_analytics.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m  i, j \u001b[39min\u001b[39;00m boltz_prob_distn: \u001b[39mpass\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "434x-YDOctB1",
        "outputId": "ace80bf4-36b6-49ab-9da6-495d467c30ad"
      },
      "outputs": [],
      "source": [
        "# mag_all_states=dict_magnetization_of_all_states(list_all_possible_states=states_nbit)\n",
        "# actual_avg_mag=avg(dict_probabilities=boltz_prob_distn, dict_observable_val_at_states=mag_all_states)\n",
        "# print(\"actual_avg_mag: \",actual_avg_mag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1crl98pgctB2"
      },
      "source": [
        "### Function to run different number of mcmc chains for a particular problem instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DCnvZVZPPgG4"
      },
      "outputs": [],
      "source": [
        "# SOME UPDATED FUNCTIONS\n",
        "def uncommon_els_2_lists(list_1,list_2):\n",
        "  return list(set(list_1).symmetric_difference(set(list_2)))\n",
        "\n",
        "def merge_2_dict(dict1, dict2):\n",
        "    return({**dict1,**dict2})\n",
        "\n",
        "def sort_dict_by_keys(dict_in:dict):\n",
        "  from collections import OrderedDict\n",
        "  return dict(OrderedDict(sorted(dict_in.items())))\n",
        "\n",
        "# some changes in clasical mcmc\n",
        "def classical_mcmc(\n",
        "    N_hops: int,\n",
        "    num_spins: int,\n",
        "    initial_state: str,\n",
        "    num_elems: int,\n",
        "    model,\n",
        "    return_last_n_states=500,\n",
        "    return_both=False,\n",
        "    temp=1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    Nhops: Number of time you want to run mcmc\n",
        "    num_spins: number of spins\n",
        "    num_elems: 2**(num_spins)\n",
        "    model:\n",
        "    return_last_n_states: (int) Number of states in the end of the M.Chain you want to consider for prob distn (default value is last 500)\n",
        "    return_both (default=False): If set to True, in addition to dict_count_return_lst_n_states, also returns 2 lists:\n",
        "                                \"list_after_transition: list of states s' obtained after transition step s->s' \" and\n",
        "                                \"list_after_acceptance_step: list of states accepted after the accepance step\".\n",
        "    Returns:\n",
        "    Last 'dict_count_return_last_n_states' elements of states so collected (default value=500). one can then deduce the distribution from it!\n",
        "    \"\"\"\n",
        "    states_obt = []\n",
        "    # current_state=f'{np.random.randint(0,num_elems):0{num_spins}b}'# bin_next_state=f'{next_state:0{num_spins}b}'\n",
        "    current_state = initial_state\n",
        "    print(\"starting with: \", current_state)\n",
        "    states_obt.append(current_state)\n",
        "\n",
        "    ## initialiiise observables\n",
        "    # observable_dict = dict([ (elem, []) for elem in observables ])\n",
        "    list_after_transition = []\n",
        "    list_after_acceptance_step = []\n",
        "\n",
        "    for i in tqdm(range(0, N_hops)):\n",
        "        # get sprime\n",
        "        s_prime = classical_transition(num_spins)\n",
        "        list_after_transition.append(s_prime)\n",
        "        # accept/reject s_prime\n",
        "        energy_s = model.get_energy(current_state)\n",
        "        energy_sprime = model.get_energy(s_prime)\n",
        "        next_state = classical_loop_accepting_state(\n",
        "            current_state, s_prime, energy_s, energy_sprime, temp=temp\n",
        "        )\n",
        "        current_state = next_state\n",
        "        list_after_acceptance_step.append(current_state)\n",
        "        states_obt.append(current_state)\n",
        "        # WE DON;T NEED TO DO THIS! # reinitiate\n",
        "        # qc_s=initialise_qc(n_spins=num_spins, bitstring=current_state)\n",
        "\n",
        "    # returns dictionary of occurences for last \"return_last_n_states\" states\n",
        "    ### added by neel 22-11-22\n",
        "    all_possible_states_nbit=states(num_spins=num_spins)\n",
        "    states_sampled=states_obt[-return_last_n_states:]\n",
        "    states_not_obtained=uncommon_els_2_lists(all_possible_states_nbit, states_sampled)\n",
        "    val_states_not_obtained=[0]*len(states_not_obtained)\n",
        "    dict_states_not_obtained=dict(zip(states_not_obtained, val_states_not_obtained ))\n",
        "    ### added by neel 22-11-22\n",
        "    dict_count_return_last_n_states = merge_2_dict(dict(Counter(states_obt[-return_last_n_states:])), dict_states_not_obtained)\n",
        "\n",
        "    if return_both:\n",
        "        to_return = (\n",
        "            dict_count_return_last_n_states,\n",
        "            list_after_transition,\n",
        "            list_after_acceptance_step,\n",
        "        )\n",
        "    else:\n",
        "        to_return = dict_count_return_last_n_states\n",
        "\n",
        "    return to_return\n",
        "\n",
        "# some changes i quantum mcmc.\n",
        "def quantum_enhanced_mcmc(\n",
        "    N_hops: int,\n",
        "    num_spins: int,\n",
        "    initial_state: str,\n",
        "    num_elems: int,\n",
        "    model: IsingEnergyFunction,\n",
        "    alpha,\n",
        "    return_last_n_states=500,\n",
        "    return_both=False,\n",
        "    temp=1,\n",
        "):\n",
        "    \"\"\"\n",
        "    version 0.2\n",
        "    Args:\n",
        "    Nhops: Number of time you want to run mcmc\n",
        "    num_spins: number of spins\n",
        "    num_elems: 2**(num_spins)\n",
        "    model:\n",
        "    alpha:\n",
        "    return_last_n_states:\n",
        "    return_both:\n",
        "    temp:\n",
        "\n",
        "    Returns:\n",
        "    Last 'return_last_n_states' elements of states so collected (default value=500). one can then deduce the distribution from it!\n",
        "    \"\"\"\n",
        "    states_obt = []\n",
        "    print(\"starting with: \", initial_state)\n",
        "\n",
        "    ## initialise quantum circuit to current_state\n",
        "    qc_s = initialise_qc(n_spins=num_spins, bitstring=initial_state)\n",
        "    current_state = initial_state\n",
        "    states_obt.append(current_state)\n",
        "    ## intialise observables\n",
        "    list_after_transition = []\n",
        "    list_after_acceptance_step = []\n",
        "\n",
        "    for i in tqdm(range(0, N_hops)):\n",
        "        # print(\"i: \", i)\n",
        "        # get sprime\n",
        "        s_prime = run_qc_quantum_step(\n",
        "            qc_initialised_to_s=qc_s, model=model, alpha=alpha, n_spins=num_spins\n",
        "        )\n",
        "        list_after_transition.append(s_prime)\n",
        "        # accept/reject s_prime\n",
        "        energy_s = model.get_energy(current_state)\n",
        "        energy_sprime = model.get_energy(s_prime)\n",
        "        next_state = classical_loop_accepting_state(\n",
        "            current_state, s_prime, energy_s, energy_sprime, temp=temp\n",
        "        )\n",
        "        current_state = next_state\n",
        "        list_after_acceptance_step.append(current_state)\n",
        "        states_obt.append(current_state)\n",
        "        ## reinitiate\n",
        "        qc_s = initialise_qc(n_spins=num_spins, bitstring=current_state)\n",
        "\n",
        "    # dict_count_return_last_n_states = Counter(\n",
        "    #     states[-return_last_n_states:]\n",
        "    # )  # dictionary of occurences for last \"return_last_n_states\" states\n",
        "    ### added by neel 22-11-22\n",
        "    all_possible_states_nbit=states(num_spins=num_spins)\n",
        "    states_sampled=states_obt[-return_last_n_states:]\n",
        "    states_not_obtained=uncommon_els_2_lists(all_possible_states_nbit, states_sampled)\n",
        "    val_states_not_obtained=[0]*len(states_not_obtained)\n",
        "    dict_states_not_obtained=dict(zip(states_not_obtained, val_states_not_obtained ))\n",
        "    ### added by neel 22-11-22\n",
        "    dict_count_return_last_n_states = merge_2_dict(dict(Counter(states_obt[-return_last_n_states:])), dict_states_not_obtained)\n",
        "\n",
        "\n",
        "    if return_both:\n",
        "        to_return = (\n",
        "            dict_count_return_last_n_states,\n",
        "            list_after_transition,\n",
        "            list_after_acceptance_step,\n",
        "        )\n",
        "    else:\n",
        "        to_return = dict_count_return_last_n_states\n",
        "\n",
        "    return to_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bQV__B7tctB4"
      },
      "outputs": [],
      "source": [
        "def run_mcmc_different_chains(num_spins:int, \n",
        "N_hops:int,num_seperate_mcmc_chains:int ,model,temp:float, \n",
        "return_last_n_states:int,return_both=False, is_quantum_mcmc=False, alpha=None ):\n",
        "\n",
        "    num_elems=2**(num_spins)\n",
        "    dict_seperate_chains_states_distn_mcmc={}\n",
        "    dict_seperate_chains_sprime_mcmc={}\n",
        "    dict_seperate_chains_accepted_mcmc={}\n",
        "    dict_seperate_chains_counts_based_on_hamming_dist={}# we can get rid of these things\n",
        "    dict_seperate_chains_energy_diff_s_and_sprime={}# for plotting histogram\n",
        "    poss_states=list(range(0,num_elems))\n",
        "    print(f\"Whether running quantum mcmc: {is_quantum_mcmc}\")\n",
        "    for chain_num in tqdm(range(0,num_seperate_mcmc_chains)):\n",
        "        init_state=np.random.choice(poss_states)\n",
        "        poss_states.remove(init_state)# to ensure that each mcmc chain starts with a different initial state\n",
        "        initial_state=f'{init_state:0{num_spins}b}'#f'{np.random.randint(0,num_elems):0{num_spins}b}'\n",
        "        if is_quantum_mcmc:\n",
        "            dict_states_mcmc, state_mcmc_after_trsn, state_mcmc_after_accept =quantum_enhanced_mcmc(N_hops, num_spins, \n",
        "                                                                                initial_state,\n",
        "                                                                                num_elems,model, \n",
        "                                                                                alpha,return_last_n_states=return_last_n_states,\n",
        "                                                                                return_both=True, temp=temp)\n",
        "        else:\n",
        "            dict_states_mcmc, state_mcmc_after_trsn, state_mcmc_after_accept =classical_mcmc(N_hops, num_spins, \n",
        "                                                                                initial_state,\n",
        "                                                                                num_elems,model, \n",
        "                                                                                return_last_n_states=return_last_n_states,\n",
        "                                                                                return_both=True, temp=temp)                                                                        \n",
        "        # sorting states in descending order of values(# occurences in mcmc chains)  for keys(states) \n",
        "        dict_states_mcmc_sorted_desc=value_sorted_dict(dict_states_mcmc, reverse=True)#dict_states_mcmc# this is where I might have to change things a little bit\n",
        "        #storing in a dict\n",
        "        dict_seperate_chains_states_distn_mcmc[chain_num]=dict_states_mcmc_sorted_desc\n",
        "        dict_seperate_chains_sprime_mcmc[chain_num]=state_mcmc_after_trsn\n",
        "        dict_seperate_chains_accepted_mcmc[chain_num]=state_mcmc_after_accept\n",
        "        dict_seperate_chains_energy_diff_s_and_sprime[chain_num]=energy_difference_related_counts(num_spins, state_mcmc_after_trsn, state_mcmc_after_accept, model_in=model)\n",
        "        dict_seperate_chains_counts_based_on_hamming_dist[chain_num]=hamming_dist_related_counts(num_spins, state_mcmc_after_trsn, state_mcmc_after_accept)\n",
        "\n",
        "    return dict_seperate_chains_states_distn_mcmc, dict_seperate_chains_sprime_mcmc, dict_seperate_chains_accepted_mcmc, dict_seperate_chains_energy_diff_s_and_sprime,dict_seperate_chains_counts_based_on_hamming_dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp0pEbzWctB6",
        "outputId": "3d580024-25d5-4bee-b044-2e15a6a3342c",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whether running quantum mcmc: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting with:  00001100110101100001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 3027.03it/s]\n",
            " 25%|██▌       | 1/4 [00:29<01:28, 29.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting with:  01000001100000110111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 4432.35it/s]\n",
            " 50%|█████     | 2/4 [00:39<00:36, 18.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting with:  11111000010000100111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 3452.86it/s]\n",
            " 75%|███████▌  | 3/4 [00:49<00:14, 14.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting with:  00000011110111111101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 3380.95it/s]\n",
            "100%|██████████| 4/4 [00:58<00:00, 14.61s/it]\n"
          ]
        }
      ],
      "source": [
        "# 10 seperate chains of classical mcmc for the given problem instance\n",
        "N_hops=1000;num_seperate_mcmc_chains=4; return_last_n_states=N_hops\n",
        "# later get rid of energy difference and hamming distance dicts.\n",
        "dict_seperate_chains_states_distn_mcmc, dict_seperate_chains_sprime_mcmc, dict_seperate_chains_accepted_mcmc, dict_seperate_chains_energy_diff_s_and_sprime,dict_seperate_chains_counts_based_on_hamming_dist=run_mcmc_different_chains(n_spins, \n",
        "N_hops, num_seperate_mcmc_chains,\n",
        "model, temp=temp, return_last_n_states=return_last_n_states,\n",
        "return_both=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCXRT6KuV6K2"
      },
      "source": [
        "# TO DO:\n",
        "get empirical distribution instead of count of occurence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZKiuBlJEvx6g"
      },
      "outputs": [],
      "source": [
        "# kl divergence\n",
        "# calculate the kl divergence\n",
        "from math import log2\n",
        "from math import sqrt\n",
        "from numpy import asarray\n",
        "import time \n",
        "\n",
        "\n",
        "# @jit(nopython= True)\n",
        "def kl_divergence(p:list, q:list):\n",
        "    return np.sum( np.array( [p[i] * log2(p[i]/q[i]) for i in range(len(p)) if p[i]!=0 ] ))\n",
        "    \n",
        "\n",
        "# calculate the js divergence\n",
        "def js_divergence(dict_p:dict, dict_q:dict):\n",
        "  t0 = time.process_time()\n",
        "  p=asarray(list(dict_p.values())); q=asarray(list(dict_q.values()))\n",
        "  t1 = time.process_time()\n",
        "  m = 0.5 * (p + q)\n",
        "  #print(\"m is:\");print(m)\n",
        "  return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
        "\n",
        "def running_js_divergence(list_chain_state_accepted:list, actual_boltz_distn:dict):\n",
        "  num_nhops=len(list_chain_state_accepted)\n",
        "  list_js_after_each_step=[]\n",
        "  possible_states=list(actual_boltz_distn.keys())\n",
        "  for step_num in tqdm(range(1,num_nhops, int(num_nhops/10 ) )):\n",
        "      print(\"step_num: \",step_num)\n",
        "      t_i = time.process_time()\n",
        "      #temp_distn_model=get_distn(list_chain_state_accepted[:step_num])\n",
        "      ### added by me today:\n",
        "      # 1. get list of unique elements in list_chain_state_accepted\n",
        "      # 2. get list of allowed state not present in list_chain_state_accepted (list_states_not_present)\n",
        "      # 3. create a temp_distn_model= \n",
        "      unique_els_list_of_accept_states=list(np.unique(list_chain_state_accepted[:step_num]))\n",
        "      \n",
        "      list_states_not_present=uncommon_els_2_lists(unique_els_list_of_accept_states,\n",
        "                                                  possible_states)\n",
        "      t1 = time.process_time()\n",
        "      \n",
        "\n",
        "      dict_states_not_obtained= dict(zip(list_states_not_present, [0]*len(list_states_not_present) ))\n",
        "      temp_distn_model= merge_2_dict(get_distn(list_chain_state_accepted[:step_num]),dict_states_not_obtained)\n",
        "      temp_distn_model= sort_dict_by_keys(temp_distn_model)#arranged in ascedning order of keys\n",
        "\n",
        "      t2 = time.process_time()\n",
        "      \n",
        "      #Merge(get_distn(list_chain_state_accepted[:step_num]), dict(zip()))\n",
        "      # print(\"temp_distribution:\")\n",
        "      # print(temp_distn_model)\n",
        "      # print(f\"len(temp_distn_model):{len(temp_distn_model)}\")\n",
        "      print('bpd :', len(actual_boltz_distn.keys()), '  mcmc-dist :', len(unique_els_list_of_accept_states))\n",
        "      # print('diff :',  len(set(temp_distn_model.keys()).intersection(actual_boltz_distn)) )\n",
        "      #js divergence\n",
        "      js_temp=js_divergence(actual_boltz_distn,temp_distn_model)\n",
        "\n",
        "      # print(js_temp)\n",
        "      list_js_after_each_step.append(js_temp)\n",
        "\n",
        "      t3 = time.process_time()\n",
        "      print(\"t_1:\", t1 - t_i) ##cflag\n",
        "      print(\"t_2:\", t2 - t1) ##cflag\n",
        "      print(\"t_3:\", t3 - t2) ##cflag\n",
        "\n",
        "      #print(f\"at step={step_num} of MCMC , KL Divergence: {js_temp}\")\n",
        "  return list_js_after_each_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "truncated_bpd = {}\n",
        "for s, prob in boltz_prob_distn.items():\n",
        "    if prob > 0.000001 : truncated_bpd[s] = prob\n",
        "    else : break \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bV7HNAYCwfLc",
        "outputId": "c3e67f6b-379d-4a58-cfec-9d06dccf3cc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step_num:  1\n",
            "bpd : 1048576   mcmc-dist : 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 1.458134685999994\n",
            "t_2: 11.246085330000028\n",
            "t_3: 5.1265201080000224\n",
            "step_num:  101\n",
            "bpd : 1048576   mcmc-dist : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8929075569999441\n",
            "t_2: 10.547859276000054\n",
            "t_3: 5.382445367999935\n",
            "step_num:  201\n",
            "bpd : 1048576   mcmc-dist : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.9702128179999363\n",
            "t_2: 10.702463350000016\n",
            "t_3: 4.859177816000056\n",
            "step_num:  301\n",
            "bpd : 1048576   mcmc-dist : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8932597210000495\n",
            "t_2: 10.510797434000096\n",
            "t_3: 4.93145583699993\n",
            "step_num:  401\n",
            "bpd : 1048576   mcmc-dist : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8399460180000915\n",
            "t_2: 11.252402302000064\n",
            "t_3: 4.9924054619998515\n",
            "step_num:  501\n",
            "bpd : 1048576   mcmc-dist : 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.9421357770002032\n",
            "t_2: 11.456219293000004\n",
            "t_3: 5.159789465999893\n",
            "step_num:  601\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.9893780350000725\n",
            "t_2: 12.245017598000004\n",
            "t_3: 5.428496016000054\n",
            "step_num:  701\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8970088149999356\n",
            "t_2: 10.603453195999919\n",
            "t_3: 5.0657802739999624\n",
            "step_num:  801\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8208844079999835\n",
            "t_2: 11.188858979000088\n",
            "t_3: 5.654068904999804\n",
            "step_num:  901\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:51<00:00, 17.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.9434861279999041\n",
            "t_2: 10.56449636100001\n",
            "t_3: 5.072765621999906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step_num:  1\n",
            "bpd : 1048576   mcmc-dist : 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.9792871989998275\n",
            "t_2: 10.8548387190001\n",
            "t_3: 5.571382400999937\n",
            "step_num:  101\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8709236709999004\n",
            "t_2: 10.255971347000013\n",
            "t_3: 5.0087077939999745\n",
            "step_num:  201\n",
            "bpd : 1048576   mcmc-dist : 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8515341449999596\n",
            "t_2: 10.488812934999942\n",
            "t_3: 5.504392183999926\n",
            "step_num:  301\n",
            "bpd : 1048576   mcmc-dist : 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 1.0124808500002018\n",
            "t_2: 10.883221661999869\n",
            "t_3: 5.1797167510001145\n",
            "step_num:  401\n",
            "bpd : 1048576   mcmc-dist : 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.8330095530000108\n",
            "t_2: 10.46051783200005\n",
            "t_3: 5.155131389999951\n",
            "step_num:  501\n",
            "bpd : 1048576   mcmc-dist : 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_1: 0.846635951999815\n",
            "t_2: 10.69870281600015\n",
            "t_3: 4.986288613999932\n",
            "step_num:  601\n"
          ]
        }
      ],
      "source": [
        "list_running_js=[]\n",
        "for i in range(0,num_seperate_mcmc_chains):# need to make this fast! it running very slowly rn\n",
        "  # print(\"i:\",i)\n",
        "  chain_accepted_state=dict_seperate_chains_accepted_mcmc[i]\n",
        "  running_js=running_js_divergence(chain_accepted_state, bpd)\n",
        "  list_running_js.append(running_js)\n",
        "  plt.figure()\n",
        "  plt.plot(np.sqrt(running_js))\n",
        "  plt.xlabel(\"mcmc steps\")\n",
        "  plt.ylabel(\"J-S Distance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPzcsTLL63Fx"
      },
      "outputs": [],
      "source": [
        "def plot_mean_running_avg(list_of_list:list, label:str):\n",
        "  mean_running_val=np.mean(np.sqrt(list_of_list),axis=0)\n",
        "  std=np.std(np.sqrt(list_of_list),axis=0)\n",
        "  plt.fill_between(range(len(mean_running_val)), mean_running_val+std/2, mean_running_val-std/2, alpha=0.1)\n",
        "  plt.plot(mean_running_val,\"-\",label=label, linewidth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2_uKweuoTiql",
        "outputId": "676ca03d-e82c-4247-f2bb-f1f2bbfacd9c"
      },
      "outputs": [],
      "source": [
        "plot_mean_running_avg(list_running_js,label=\"cl mcmc\")\n",
        "plt.xlabel(\"mcmc iter\");plt.ylabel(\"JS Distance\");plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHxrMf5ActB8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "### data for plotting running average magnetization (averaged over \"num_seperate_mcmc_chains\" number of mcmc chains):\n",
        "first_few=N_hops# \n",
        "\n",
        "list_for_df_running_avg_seperate_mcmc = []\n",
        "for m in range(0, num_seperate_mcmc_chains):\n",
        "    list_for_df_running_avg_seperate_mcmc.append(running_avg_magnetization_as_list(dict_seperate_chains_accepted_mcmc[m][:first_few+1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "pSFcxIerRTLM",
        "outputId": "50794ccf-3a9c-41b8-820e-f0b996ba7316"
      },
      "outputs": [],
      "source": [
        "mean_magnetization = np.mean(list_for_df_running_avg_seperate_mcmc, axis=0) - actual_avg_mag\n",
        "std_magnetization = np.std(list_for_df_running_avg_seperate_mcmc, axis=0)\n",
        "plt.fill_between(range(len(mean_magnetization)), mean_magnetization+std_magnetization/2, mean_magnetization-std_magnetization/2, alpha=0.1)\n",
        "\n",
        "plt.plot(mean_magnetization,\":\" ,label=\"Cl mcmc\", linewidth=2)\n",
        "\n",
        "plt.axhline(y=0,linestyle=\"-\", color=\"k\" ,label=\"Actual\")\n",
        "plt.legend()\n",
        "# plt.ylim(0, 3)\n",
        "plt.ylabel(\"Magnetization error\")\n",
        "plt.xlabel(\"MCMC steps\")\n",
        "plt.xscale(\"log\")\n",
        "# plt.yscale(\"log\")\n",
        "# plt.ylim(1e-2, 3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDaxuS9BctB9"
      },
      "outputs": [],
      "source": [
        "# pandas data_frame for prob distn obtained from different mcmc chains\n",
        "def fn_get_dataframe_diff_mcmc_chains_same_problem_instance(dict_seperate_chains_states_mcmc):\n",
        "    df=pd.DataFrame(dict_seperate_chains_states_mcmc)\n",
        "    df=df.fillna(0)\n",
        "    return df\n",
        "\n",
        "def get_dict_mean_occurences(df_seperate_chains_mcmc_states_occurences):\n",
        "    mean_occurences=df_seperate_chains_mcmc_states_occurences.mean(axis=1)\n",
        "    #print(\"mean occurences:\"); print(mean_occurences)\n",
        "    #print(f\"type(mean_occurences): {type(mean_occurences)}\")\n",
        "    dict_mean_occurences=mean_occurences.to_dict()# mean number of occurences; we took mean of data obtained for mcmc chains\n",
        "    # plt.figure(1); mean_occurences.plot.bar()\n",
        "    return dict_mean_occurences\n",
        "\n",
        "def get_empirical_distn(dict_mean_occurences):\n",
        "    sum_of_counts = sum(dict_mean_occurences.values())\n",
        "    empirical_probs=list(np.array(list(dict_mean_occurences.values()))/sum_of_counts)\n",
        "    ### Prob distribution, sorted in descending order of prob values\n",
        "    dict_empirical_prob_distn=dict(zip(list(dict_mean_occurences.keys()), empirical_probs ))\n",
        "    return dict_empirical_prob_distn\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "G8UZANBnctB-",
        "outputId": "38d5e6fe-020c-4eb6-d56e-004124ab9780"
      },
      "outputs": [],
      "source": [
        "### for classical mcmc\n",
        "df_1=fn_get_dataframe_diff_mcmc_chains_same_problem_instance(dict_seperate_chains_states_distn_mcmc)\n",
        "dict_mean_occurences=get_dict_mean_occurences(df_1)\n",
        "dict_empirical_cl_prob_distn=get_empirical_distn(dict_mean_occurences)\n",
        "\n",
        "plt.figure(1)\n",
        "plot_multiple_bargraphs(list_of_dicts=[boltz_prob_distn, dict_empirical_cl_prob_distn],\n",
        "                        list_labels=[\"analytical\",\"classical-uniform MCMC\"],\n",
        "                        list_normalise=[False,False] ,plot_first_few=16,  \n",
        "                        sort_desc=True,figsize=(10,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyS-4_r1ctCA",
        "outputId": "374fb60f-b802-4320-bf57-c9e5300cff1a"
      },
      "outputs": [],
      "source": [
        "np.sqrt(js_divergence(boltz_prob_distn,dict_empirical_cl_prob_distn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD-dnVTbctCB"
      },
      "source": [
        "### Quantum enhanced MCMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEKd8YaectCC",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 10 seperate chains of quantum mcmc for the given problem instance\n",
        "N_hops_q=1000;num_seperate_mcmc_chains_q=4; return_last_n_states_q=N_hops_q\n",
        "dict_seperate_chains_states_distn_mcmc_q, dict_seperate_chains_sprime_mcmc_q, dict_seperate_chains_accepted_mcmc_q, dict_seperate_chains_energy_diff_s_and_sprime_q,dict_seperate_chains_counts_based_on_hamming_dist_q=run_mcmc_different_chains(n_spins, \n",
        "N_hops_q, num_seperate_mcmc_chains_q,\n",
        "model, temp=temp, return_last_n_states=return_last_n_states_q,\n",
        "return_both=True, is_quantum_mcmc=True, alpha=alpha )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FjePWBsk_TVV",
        "outputId": "cba160a6-f48b-4fc6-d382-f3d27b688c2b"
      },
      "outputs": [],
      "source": [
        "list_running_js_q=[]\n",
        "for i in range(0,num_seperate_mcmc_chains):\n",
        "  print(\"i:\",i)\n",
        "  chain_accepted_state_q=dict_seperate_chains_accepted_mcmc_q[i]\n",
        "  running_js_q=running_js_divergence(chain_accepted_state_q,bpd)\n",
        "  list_running_js_q.append(running_js_q)\n",
        "  plt.figure()\n",
        "  plt.plot(np.sqrt(running_js_q))\n",
        "  plt.xlabel(\"mcmc steps\")\n",
        "  plt.ylabel(\"J-S Distance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "AyS1e-n1_TMv",
        "outputId": "f0b5fb39-40ef-42a2-f1c5-cbb7fdf009c6"
      },
      "outputs": [],
      "source": [
        "plot_mean_running_avg(list_running_js_q,label=\"q mcmc\")\n",
        "plot_mean_running_avg(list_running_js,label=\"cl mcmc\")\n",
        "plt.xlabel(\"mcmc iter\");plt.ylabel(\"JS Distance\");plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7uFqY-ZRTLR"
      },
      "outputs": [],
      "source": [
        "### data for plotting running average magnetization 5 cases seperately:\n",
        "first_few=N_hops_q# \n",
        "list_for_df_running_avg_seperate_mcmc_q = []\n",
        "for m in range(0, num_seperate_mcmc_chains_q):\n",
        "    list_for_df_running_avg_seperate_mcmc_q.append(running_avg_magnetization_as_list(dict_seperate_chains_accepted_mcmc_q[m][:first_few+1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "droVL2bKctCF",
        "outputId": "49f65616-9a9b-44b0-b9a4-bbfe06dc1b27"
      },
      "outputs": [],
      "source": [
        "mean_magnetization_q = np.mean(list_for_df_running_avg_seperate_mcmc_q, axis=0) - actual_avg_mag\n",
        "std_magnetization_q = np.std(list_for_df_running_avg_seperate_mcmc_q, axis=0)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.fill_between(range(len(mean_magnetization)), mean_magnetization+std_magnetization/2, mean_magnetization-std_magnetization/2, alpha=0.1)\n",
        "plt.fill_between(range(len(mean_magnetization_q)), mean_magnetization_q+std_magnetization_q/2, mean_magnetization_q-std_magnetization_q/2, alpha=0.1)\n",
        "\n",
        "# magnetization_of_all_states=dict_magnetization_of_all_states(states_nbit)\n",
        "# actual_avg_mag=avg(dict_probabilities=boltz_prob_distn, dict_observable_val_at_states=magnetization_of_all_states)\n",
        "\n",
        "plt.plot(mean_magnetization,\"-\" ,label=\"classical mcmc\")\n",
        "plt.plot(mean_magnetization_q,\"-\" ,label=\"quant mcmc\")\n",
        "plt.axhline(y=0,linestyle=\"--\", color=\"k\" ,label=\"Actual\")\n",
        "plt.legend()\n",
        "#plt.ylim(-1, 1)\n",
        "plt.ylabel(\"Magnetization error\")\n",
        "plt.xlabel(\"MCMC steps\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "FFCb1B5DctCG",
        "outputId": "320c5ea7-fff8-45b4-9695-e3c059e741a6"
      },
      "outputs": [],
      "source": [
        "### for quantum mcmc\n",
        "df_q=fn_get_dataframe_diff_mcmc_chains_same_problem_instance(dict_seperate_chains_states_distn_mcmc_q)\n",
        "dict_mean_occurences_q=get_dict_mean_occurences(df_q)\n",
        "dict_empirical_prob_distn_q=get_empirical_distn(dict_mean_occurences_q)\n",
        "\n",
        "plt.figure(1)\n",
        "plot_multiple_bargraphs(list_of_dicts=[boltz_prob_distn, dict_empirical_cl_prob_distn,dict_empirical_prob_distn_q],\n",
        "                        list_labels=[\"analytical\",\"Cl-MCMC\",\"Quant MCMC\"],\n",
        "                        list_normalise=[False,False,False] ,plot_first_few=10,  \n",
        "                        sort_desc=True,figsize=(10,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o8Nf5FXctCH",
        "outputId": "8377afbe-2a0b-4a5b-de17-7304f0366ee1"
      },
      "outputs": [],
      "source": [
        "print(\"JS distance quantum case:\");\n",
        "print(np.sqrt(js_divergence(dict_empirical_prob_distn_q,boltz_prob_distn)))\n",
        "print(\"JS distance classical case:\")\n",
        "print(np.sqrt(js_divergence(dict_empirical_cl_prob_distn,boltz_prob_distn)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qti-6LJJEdXF"
      },
      "outputs": [],
      "source": [
        "# def similarity_coefficient(target_prob_distn:dict, model_prob_distn:dict):\n",
        "#   \"\"\" Returns: Bhattacharya coefficient BC(P,Q)= \\sum_{i} sqrt(P(i)*Q(i))\n",
        "#       Args: target_prob_distn: P\n",
        "#             model_prob_distn: Q, approximates P\n",
        "#   \"\"\"\n",
        "#   list_prob_model=list(target_prob_distn.values())\n",
        "#   list_prob_data=list(model_prob_distn.values())\n",
        "#   list_keys_model=list(model_prob_distn.keys())\n",
        "\n",
        "#   sim_coeff=0\n",
        "#   for i in range(0,len(list_keys_model)):\n",
        "#       if(list_prob_data[i]== 0 or list_prob_model==0):\n",
        "#           to_return+= 0\n",
        "#       else:\n",
        "#         sim_coeff+=np.sqrt(list_prob_data[i]*list_prob_model[i])\n",
        "#   return sim_coeff\n",
        "\n",
        "# def running_sim_coeff(list_chain_state_accepted:list,actual_boltz_distn:dict):\n",
        "#   num_nhops=len(list_chain_state_accepted)\n",
        "#   list_sim_coeff_after_each_step=[]\n",
        "#   for step_num in range(1,num_nhops):\n",
        "#     #print(\"step_num: \",step_num)\n",
        "#     temp_distn_model=get_distn(list_chain_state_accepted[:step_num])\n",
        "#     #print(\"temp_distribution:\")\n",
        "#     #print(temp_distn_model)\n",
        "#     sim_coeff_temp=similarity_coefficient(actual_boltz_distn,temp_distn_model)\n",
        "#     list_sim_coeff_after_each_step.append(sim_coeff_temp)\n",
        "#     print(f\"at step={step_num} of MCMC , bhatt.coeff: {sim_coeff_temp}\")\n",
        "#   return list_sim_coeff_after_each_step"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
